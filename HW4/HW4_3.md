#### Association rules for grocery purchases

Since `groceries.txt` is a text document, we first set up some packages
and use the **“reader” functions** professor created in the
`tm_examples.R` file.

##### create functions read document.

we use the `readerPlain` function as professor used in `tm_examples.R`.
I also shows the file’s meta data.

    ##   author       : character(0)
    ##   datetimestamp: 2022-05-02 21:06:59
    ##   description  : character(0)
    ##   heading      : character(0)
    ##   id           : https://raw.githubusercontent.com/jgscott/ECO395M/master/data/groceries.txt
    ##   language     : en
    ##   origin       : character(0)

    ##         Length Class            Mode     
    ## content 9835   -none-           character
    ## meta       7   TextDocumentMeta list

##### create a list of baskets

In this document, we can only create a list of baskets based on each
row, since there is no heading or other variables can be used to split.

we first create a text mining ‘corpus’ with the initial document. Since
there is no number in the file, and each letter is lowercase, we only
need to use `,` to split each item. So we pass the process of
pre-processing/tokenization steps. We have already known there are 9835
rows in this file, so we will split them into 9835 rows and split each
row’s elements by `,`

We can get first row in the baskt like:

    ## [1] "citrus fruit"        "semi-finished bread" "margarine"          
    ## [4] "ready soups"

Then we use `lappy` function to remove duplicates (“de-dupe”). Then cast
this resulting list of playlists as a special arules “transactions”
class. Then we can see the summary of basket based on “transactions”
rules.

    ## transactions as itemMatrix in sparse format with
    ##  9835 rows (elements/itemsets/transactions) and
    ##  169 columns (items) and a density of 0.02609146 
    ## 
    ## most frequent items:
    ##       whole milk other vegetables       rolls/buns             soda 
    ##             2513             1903             1809             1715 
    ##           yogurt          (Other) 
    ##             1372            34055 
    ## 
    ## element (itemset/transaction) length distribution:
    ## sizes
    ##    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 
    ## 2159 1643 1299 1005  855  645  545  438  350  246  182  117   78   77   55   46 
    ##   17   18   19   20   21   22   23   24   26   27   28   29   32 
    ##   29   14   14    9   11    4    6    1    1    1    1    3    1 
    ## 
    ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    ##   1.000   2.000   3.000   4.409   6.000  32.000 
    ## 
    ## includes extended item information - examples:
    ##             labels
    ## 1 abrasive cleaner
    ## 2 artif. sweetener
    ## 3   baby cosmetics

##### create association rules

Then Now run the ‘apriori’ algorithm, look at rules with support &gt;
.01 & confidence &gt;.1 & length (# artists) &lt;= 2,

we firstly look at the output… so many rules! Since there are 339 rules,
I want to reset the rules requirement.

    ## set of 339 rules

Then I look at rules with support &gt; .03 & confidence &gt;.1 & length
(# artists) &lt;= 2,

    ## set of 122 rules

Now we have 122 rules, with requirement : **support &gt; .02 &
confidence &gt;.1 & length (# artists) &lt;= 2**. We can continue to
analyze them and to set the threshold as we want.

##### Futher Analysis

Under the above threshold, about 100 rules we got. We first plot all the
rules in (support, confidence) space notice that high lift rules tend to
have low support.

    ## To reduce overplotting, jitter is added! Use jitter = 0 to prevent jitter.

![](HW4_3_files/figure-markdown_strict/plot%20rules-1.png)

    ## To reduce overplotting, jitter is added! Use jitter = 0 to prevent jitter.

![](HW4_3_files/figure-markdown_strict/plot%20rules-2.png)

We can estimate that high lift tend to have low support. Also, high
confidence tend to have low support. This is also in line with the
prediction of chance.

Now, we can create a new subset and show the result, although we have
122 rules now, it is too many to graph it, so we set a new subset, with
threshold **support &gt; .04 & confidence &gt;.1 **, and now we can see
that only 26 rules still exist.

    ## set of 26 rules

And we can get the graph based on the new subset

![](HW4_3_files/figure-markdown_strict/plot%20new%20subset%20-1.png)

I think the association rules make sense, it shows several major
commodity categories. For example, it shows root vegetables and other
vegetables, and there are many arrows point to them. Also, we can plot
the initial association rules, but due to some reasons, it can only plot
part of it.

    ## Warning: Unknown control parameters: size

    ## Available control parameters (with default values):
    ## layout    =  stress
    ## circular  =  FALSE
    ## ggraphdots    =  NULL
    ## edges     =  <environment>
    ## nodes     =  <environment>
    ## nodetext  =  <environment>
    ## colors    =  c("#EE0000FF", "#EEEEEEFF")
    ## engine    =  ggplot2
    ## max   =  100
    ## verbose   =  FALSE

    ## Warning: Too many rules supplied. Only plotting the best 100 using
    ## 'lift' (change control parameter max if needed).

![](HW4_3_files/figure-markdown_strict/show%20the%20basketrules%20plot-1.png)

Now we can see clearly that association rules is meaningful, since it
list a large number of commodity and specific combination. In addition,
for many generalized categories of goods, there are many arrows pointing
to them, it fits the logic of my practical life.
